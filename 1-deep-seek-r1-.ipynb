# ğŸŒ DeepSeek-R1 + Azure AI for Infra Optimization ğŸš€

Welcome to the DeepSeek-R1 + Azure AI notebook for **cloud infrastructure optimization and cost-performance analysis**.

**DeepSeek-R1** is a state-of-the-art reasoning model fine-tuned with reinforcement learning and supervised training. 
It excels at analyzing complex environmentsâ€”perfect for Azure infrastructure scenarios that require deep insights and decisions.

In this notebook, you'll learn how to:

1. ğŸ”§ **Initialize** the `ChatCompletionsClient` for Azure serverless inference endpoints
2. ğŸ’¬ **Chat** with DeepSeek-R1 to extract reasoning and recommendations
3. ğŸ“Š **Analyze** Azure infrastructure for cost, performance, and scalability
4. ğŸ§  **Leverage** the 128K context window to evaluate large-scale configurations and cost reports

---

ğŸ› ï¸ **Why DeepSeek-R1 for Azure Infra?**

- ğŸ”„ **Chain-of-Thought Reasoning**: Ideal for evaluating multi-step cloud architectures
- ğŸ“š **Massive Context Support**: 128,000 tokens to reason over entire reports, Bicep templates, and ARM deployments
- âš™ï¸ **Efficient Intelligence**: 37B active parameters focused on actionable insights
- ğŸ”’ **Built-in Safety Filters**: Keeps recommendations reliable and secure

Use this model to simulate what an Azure Solutions Architect might doâ€”but at scale and with speed.

Letâ€™s dive in and optimize your Azure environment intelligently.


## 1. Setup & Authentication

Required packages:
- `azure-ai-inference`: For chat completions
- `python-dotenv`: For environment variables

.env file requirements:
```bash
AZURE_INFERENCE_ENDPOINT=<your-endpoint-url>
AZURE_INFERENCE_KEY=<your-api-key>
MODEL_NAME=DeepSeek-R1
```

import os
import re
from dotenv import load_dotenv
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

# Load environment
load_dotenv()
endpoint = os.getenv("AZURE_INFERENCE_ENDPOINT")
key = os.getenv("AZURE_INFERENCE_KEY")
model_name = os.getenv("MODEL_NAMEDS", "DeepSeek-R1")

# Initialize client
try:
    client = ChatCompletionsClient(
        endpoint=endpoint,
        credential=AzureKeyCredential(key),
        headers={"x-ms-model-mesh-model-name": model_name}  # Add the model name in the header
    )
    print("âœ… Client initialized | Model:", client.get_model_info().model_name)
except Exception as e:
    print("âŒ Initialization failed:", e)


## 3. Technical Problem Solving ğŸ’»

Showcase coding/optimization capabilities:



def solve_technical_problem(problem):
    """Solve complex technical problems with structured reasoning"""
    response = client.complete(
        messages=[
            SystemMessage(content="You are a FinOps expert specializing in Azure cost optimization. Provide detailed, actionable advice."),
            UserMessage(content=f"{problem} Please reason step by step and highlight key recommendations.")
        ],
        model=model_name,
        temperature=0.3,
        max_tokens=2048
    )
    
    return response.choices[0].message.content

# FinOps for Azure optimization examples
problem = """As a FinOps specialist, analyze how to optimize costs for an Azure environment with 50 VMs (mix of D-series and F-series) 
running in West Europe. Most VMs are running 24/7, but actual usage patterns show 60% utilization during business hours and 15% during nights/weekends. 
What cost-saving strategies would you recommend, including newer VM generations that might offer better performance/cost ratio?"""

print("ğŸ’° FinOps Challenge:", problem)
print("\nğŸ’¡ Optimization Strategy:", solve_technical_problem(problem))

